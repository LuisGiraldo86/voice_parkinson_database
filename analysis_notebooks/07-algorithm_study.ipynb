{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ae330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "library_path = os.path.abspath('..')\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "\n",
    "PLOTS_PATH = os.path.join(library_path, 'plots')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Diagnosis_Severity_PD_Voice\"]\n",
    "collection = db[\"studies\"]\n",
    "\n",
    "print(\"ðŸ”„ Loading studies from MongoDB...\")\n",
    "fields_to_extract = {\n",
    "    \"doi\"             : 1,\n",
    "    \"title\"           : 1,\n",
    "    \"year\"            : 1, \n",
    "    \"study_id\"        : 1,\n",
    "    \"ml_approaches\"   : 1,\n",
    "    \"problem\"         : 1,\n",
    "    '_id'             : 0\n",
    "}  # 1 = include, 0 = exclude\n",
    "studies_cursor = collection.find({}, fields_to_extract)\n",
    "studies_list = list(studies_cursor)\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total studies loaded: {len(studies_list)}\")\n",
    "print(f\"ðŸ“„ Sample document keys: {list(studies_list[0].keys()) if studies_list else 'No documents found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69091bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaling(experiment_list:list)->list:\n",
    "\n",
    "    scaling_list = []\n",
    "\n",
    "    for experiment in experiment_list:\n",
    "        scaling = experiment.get('scaling')\n",
    "        if scaling is None:\n",
    "            scaling = []\n",
    "        scaling_list += scaling\n",
    "\n",
    "    return list(set(scaling_list))\n",
    "\n",
    "def experiments_with_scaling(experiment_list: list)->int:\n",
    "\n",
    "    count = 0\n",
    "    for experiment in experiment_list:\n",
    "        if experiment.get('scaling') is not None:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def get_algorithms(experiment_list:list)->list:\n",
    "\n",
    "    algorithm_list = []\n",
    "\n",
    "    for experiment in experiment_list:\n",
    "        algorithms = experiment.get('algorithm')\n",
    "        if algorithms is None:\n",
    "            continue\n",
    "        algorithm_list.append(algorithms)\n",
    "\n",
    "    return list(set(algorithm_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e194c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(studies_list)\n",
    "experiment_df['num_experiments'] = experiment_df['ml_approaches'].apply(lambda x: len(x))\n",
    "experiment_df['exp_with_scaling'] = experiment_df['ml_approaches'].apply(lambda x: experiments_with_scaling(x))\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b19b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = experiment_df['num_experiments'].sum()\n",
    "experiments_with_scaling = experiment_df['exp_with_scaling'].sum()\n",
    "\n",
    "print(f\"Total number of experiments: {num_experiments}\")\n",
    "print(f\"Number of experiments with scaling: {experiments_with_scaling}\")\n",
    "print(f\"NNumber of experiments without scaling: {num_experiments-experiments_with_scaling}\")\n",
    "print(f\"Percentage of experiments with scaling: {experiments_with_scaling/num_experiments*100:.2f}%\")\n",
    "print(f\"Number of papers: {experiment_df['doi'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91487d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['scaling'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_scaling(x)\n",
    ")\n",
    "experiment_df['algorithms'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_algorithms(x)\n",
    ")\n",
    "algorithm_df = experiment_df.explode('algorithms')\n",
    "algorithm_df = algorithm_df.explode('scaling')\n",
    "algorithm_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859740d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_df['base_algorithm'] = algorithm_df['algorithms'].apply(\n",
    "    lambda x: x.split(':')[0] if isinstance(x, str) else x)\n",
    "algorithm_df['base_algorithm'] = algorithm_df['base_algorithm'].apply(lambda x: x.split('(')[0].strip())\n",
    "algorithm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique algorithms: {algorithm_df['base_algorithm'].nunique():,}\")\n",
    "print(f\"Total of papers: {algorithm_df['doi'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f98644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_technique_name(technique):\n",
    "    \"\"\"\n",
    "    Clean technique names by extracting the base strategy.\n",
    "    Handles both colon-separated and parentheses-separated details.\n",
    "    \"\"\"\n",
    "    if not isinstance(technique, str):\n",
    "        return str(technique)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    cleaned = technique.strip()\n",
    "    \n",
    "    # Handle specific name standardizations first\n",
    "    if (cleaned == \"CDIL-CNN Experiment 3\" or \n",
    "        cleaned == \"CDIL-CNN Experiment 1\" or \n",
    "        cleaned == \"CDIL-CNN Experiment 2\"):\n",
    "        cleaned = \"CDIL-CNN\"\n",
    "\n",
    "    if (cleaned == \"InceptionTime Experiment 1\" or \n",
    "        cleaned == \"InceptionTime Experiment 2\" or \n",
    "        cleaned == \"InceptionTime Experiment 3\"):\n",
    "        cleaned = \"InceptionTime\"\n",
    "\n",
    "    if (cleaned == \"LSTM-FCN Experiment 1\" or \n",
    "        cleaned == \"LSTM-FCN Experiment 2\" or \n",
    "        cleaned == \"LSTM-FCN Experiment 3\"):\n",
    "        cleaned = \"LSTM-FCN\"\n",
    "\n",
    "    # Additional cleanup for common patterns\n",
    "    # Remove trailing dashes or other separators\n",
    "    cleaned = cleaned.rstrip(' -â€“â€”_')\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_df['cleaned_algorithm'] = algorithm_df['base_algorithm'].apply(clean_technique_name)\n",
    "algorithm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ce5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = algorithm_df.groupby(by=['doi', 'problem'], as_index=False).agg({'cleaned_algorithm': set})\n",
    "tech_by_paper = tech_by_paper.explode('cleaned_algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9218041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Get top 10 algorithms\n",
    "technique_rank = (\n",
    "    tech_by_paper['cleaned_algorithm']\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "technique_rank.columns = ['algorithm', 'count']\n",
    "top10 = technique_rank['algorithm'].head(10).tolist()\n",
    "\n",
    "# 2. Filter only top 10\n",
    "filtered = tech_by_paper[tech_by_paper['cleaned_algorithm'].isin(top10)].copy()\n",
    "\n",
    "# Standardize problem names\n",
    "filtered['problem'] = filtered['problem'].replace({\n",
    "    \"Parkinson's disease diagnosis\": 'Diagnosis',\n",
    "    \"Parkinson's disease severity stage classification\": 'Severity'\n",
    "})\n",
    "\n",
    "# 3. Count occurrences\n",
    "alg_prob_counts = (\n",
    "    filtered\n",
    "    .groupby(['cleaned_algorithm', 'problem'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "\n",
    "# 4. Pivot raw counts\n",
    "pivot = (\n",
    "    alg_prob_counts\n",
    "    .pivot(index='cleaned_algorithm', columns='problem', values='count')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 5. Percent pivot (100% stacked data)\n",
    "pivot_percent = pivot.div(pivot.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# 6. Order algorithms bottomâ†’top\n",
    "ordered_algorithms = technique_rank['algorithm'].head(10).tolist()[::-1]\n",
    "pivot_percent = pivot_percent.reindex(ordered_algorithms)\n",
    "\n",
    "# 7. Plot 100% stacked bar chart\n",
    "ax = pivot_percent.plot(\n",
    "    kind='barh',\n",
    "    stacked=True,\n",
    "    figsize=(12, 7),\n",
    "    colormap='tab20'\n",
    ")\n",
    "\n",
    "plt.title('Top 10 Algorithms â€” Percent Split by Problem Type')\n",
    "plt.xlabel('Percent')\n",
    "plt.ylabel('Algorithm')\n",
    "\n",
    "# 8. Add percent labels inside segments\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "colors = plt.cm.tab20.colors  # consistent order\n",
    "\n",
    "for y, alg in enumerate(ordered_algorithms):\n",
    "    row = pivot_percent.loc[alg]\n",
    "    x_pos = 0\n",
    "\n",
    "    for problem, color, percent in zip(pivot_percent.columns, colors, row):\n",
    "        if percent > 0:\n",
    "            # compute brightness for readable text\n",
    "            r, g, b = mcolors.to_rgb(color)\n",
    "            brightness = 0.299*r + 0.587*g + 0.114*b\n",
    "            text_color = 'black' if brightness > 0.7 else 'white'\n",
    "\n",
    "            ax.text(\n",
    "                x_pos + percent / 2,\n",
    "                y,\n",
    "                f\"{percent:.1f}%\",\n",
    "                va='center',\n",
    "                ha='center',\n",
    "                fontsize=9,\n",
    "                color=text_color,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "        x_pos += percent\n",
    "\n",
    "plt.legend(title='Problem Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e79ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_rank = tech_by_paper['cleaned_algorithm'].value_counts().reset_index()\n",
    "technique_rank.columns = ['algorithm', 'count']\n",
    "technique_rank['percentage'] = np.round(technique_rank['count'] / technique_rank['count'].sum() * 100, 2)\n",
    "technique_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def break_long_names(name, max_len=22, max_lines=3):\n",
    "    wrapped = textwrap.wrap(\n",
    "        name,\n",
    "        width=max_len,\n",
    "        break_long_words=False,\n",
    "        break_on_hyphens=False\n",
    "    )\n",
    "\n",
    "    # Limit number of lines\n",
    "    if len(wrapped) > max_lines:\n",
    "        wrapped = wrapped[:max_lines]\n",
    "        wrapped[-1] += \"â€¦\"\n",
    "\n",
    "    return \"\\n\".join(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d3fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_techniques = technique_rank.head(10)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Figure size (single-column journal size)\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = top10_techniques['percentage']\n",
    "\n",
    "# Bar plot\n",
    "ax = sns.barplot(\n",
    "    x=top10_techniques['count'],\n",
    "    y=top10_techniques['algorithm'],\n",
    "    color=\"#4C72B0\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Most Used Algorithms\")\n",
    "ax.set_xlabel(\"Number of Papers\")\n",
    "ax.set_ylabel(\"Algorithm\")\n",
    "\n",
    "# Ticks\n",
    "ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "# Add value and percentage labels on bars (closer to the end of the bars)\n",
    "for i, (v, pct) in enumerate(zip(top10_techniques['count'], percentages)):\n",
    "    ax.text(v - 0.5, i, f\"{pct:.1f}%\", va='center', ha='right', fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "# Improve grid appearance\n",
    "ax.grid(axis='x', color=\"#E5E5E5\")\n",
    "ax.grid(axis='y', visible=False)\n",
    "\n",
    "# Tight layout for clean export\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'ml_algorithms_barplot.svg'), dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0968d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_df['scaling'] = algorithm_df['scaling'].fillna('No Scaling')\n",
    "algorithm_df['has_scale'] = algorithm_df['scaling'].apply(lambda x: 0 if x == 'No Scaling' else 1)\n",
    "algorithm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs_scaled = algorithm_df.groupby(by=['cleaned_algorithm', 'has_scale'], as_index=False).size()\n",
    "top10_algs_scaled = algs_scaled[algs_scaled['cleaned_algorithm'].isin(top10)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# 1. Pivot into wide format\n",
    "pivot_scaled = (\n",
    "    top10_algs_scaled\n",
    "    .pivot(index='cleaned_algorithm', columns='has_scale', values='size')\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "# 2. Order algorithms as before (reverse top10 list)\n",
    "pivot_scaled = pivot_scaled.reindex(top10[::-1])\n",
    "\n",
    "# 3. Convert counts â†’ percent per algorithm\n",
    "pivot_scaled_percent = pivot_scaled.div(pivot_scaled.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# 4. Plot using same style as previous figure\n",
    "ax = pivot_scaled_percent.plot(\n",
    "    kind='barh',\n",
    "    stacked=True,\n",
    "    figsize=(9, 6),\n",
    "    colormap='tab20'     # <<< same colormap as previous plot\n",
    ")\n",
    "\n",
    "plt.title('Top 10 Algorithms: Scaling Usage (Percent)')\n",
    "plt.xlabel('Percent of Papers')\n",
    "plt.ylabel('Algorithm')\n",
    "\n",
    "# 5. Legend update (consistent placement + style)\n",
    "plt.legend(\n",
    "    ['Yes', 'No'],\n",
    "    title='Scaling',\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc='upper left'\n",
    ")\n",
    "\n",
    "# 6. Add percentage labels inside the stacked bars (same font logic)\n",
    "colors = plt.cm.tab20.colors   # use matching colors\n",
    "\n",
    "for y, alg in enumerate(pivot_scaled_percent.index):\n",
    "    row = pivot_scaled_percent.loc[alg]\n",
    "    x_pos = 0\n",
    "\n",
    "    for (col, color, percent) in zip(pivot_scaled_percent.columns, colors, row):\n",
    "\n",
    "        if percent > 0:\n",
    "            # dynamic text color (same as previous plot)\n",
    "            r, g, b = mcolors.to_rgb(color)\n",
    "            brightness = (0.299*r + 0.587*g + 0.114*b)\n",
    "            text_color = 'black' if brightness > 0.7 else 'white'\n",
    "\n",
    "            ax.text(\n",
    "                x_pos + percent/2,\n",
    "                y,\n",
    "                f\"{percent:.1f}%\",\n",
    "                va='center',\n",
    "                ha='center',\n",
    "                fontsize=11,\n",
    "                color=text_color,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "        x_pos += percent\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'ml_algorithms_scaling_barplot.svg'), dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_algs = algorithm_df[algorithm_df['cleaned_algorithm'].isin(top10)].reset_index(drop=True)\n",
    "top10_algs =top10_algs.groupby(by=['doi'], as_index=False).agg(\n",
    "    {'year': 'first',\n",
    "     'cleaned_algorithm': list}\n",
    ").explode('cleaned_algorithm')\n",
    "top10_algs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_timeline = top10_algs.groupby(by=['year', 'cleaned_algorithm'], as_index=False).size()\n",
    "top10_timeline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db34f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot = top10_timeline.pivot(index='year', columns='cleaned_algorithm', values='size')\n",
    "\n",
    "plt.figure()\n",
    "for algo in pivot.columns:\n",
    "    plt.plot(pivot.index, pivot[algo], label=algo)\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b650999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Ensure sorted time axis\n",
    "df = top10_timeline.sort_values(\"year\")\n",
    "\n",
    "algorithms = df[\"cleaned_algorithm\"].unique()\n",
    "n_algos = len(algorithms)\n",
    "\n",
    "# Grid layout (you can adjust this)\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n_algos / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 3*n_rows), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, algo in enumerate(algorithms):\n",
    "    ax = axes[i]\n",
    "    sub = df[df[\"cleaned_algorithm\"] == algo]\n",
    "    \n",
    "    ax.plot(sub[\"year\"], sub[\"size\"])\n",
    "    ax.set_title(algo)\n",
    "\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "\n",
    "# Remove empty subplots (if any)\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'ml_algorithms_timeline_subplots.svg'), dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e77871",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_df = algorithm_df[algorithm_df['cleaned_algorithm'] == 'Multilayer Perceptron'].reset_index(drop=True)\n",
    "mlp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3bbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_df[algorithm_df['algorithms']=='Support Vector Machine: Quadratic (Hardware Implementation)']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-db-Uw6PKE_M-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
