{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59196348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "library_path = os.path.abspath('..')\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "\n",
    "PLOTS_PATH = os.path.join(library_path, 'plots')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Diagnosis_Severity_PD_Voice\"]\n",
    "collection = db[\"studies\"]\n",
    "\n",
    "print(\"ðŸ”„ Loading studies from MongoDB...\")\n",
    "fields_to_extract = {\n",
    "    \"doi\"             : 1,\n",
    "    \"title\"           : 1,\n",
    "    \"year\"            : 1, \n",
    "    \"study_id\"        : 1,\n",
    "    \"ml_approaches\"   : 1,\n",
    "    '_id'             : 0\n",
    "}  # 1 = include, 0 = exclude\n",
    "studies_cursor = collection.find({}, fields_to_extract)\n",
    "studies_list = list(studies_cursor)\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total studies loaded: {len(studies_list)}\")\n",
    "print(f\"ðŸ“„ Sample document keys: {list(studies_list[0].keys()) if studies_list else 'No documents found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extraction(experiment_list:list)->list:\n",
    "\n",
    "    feat_extract = []\n",
    "\n",
    "    for experiment in experiment_list:\n",
    "        extraction_pipe = experiment.get('feature_extraction')\n",
    "        if extraction_pipe is None:\n",
    "            extraction_pipe = []\n",
    "        feat_extract += extraction_pipe\n",
    "\n",
    "    return list(set(feat_extract))\n",
    "\n",
    "def experiments_with_feat_ext(experiment_list: list)->int:\n",
    "\n",
    "    count = 0\n",
    "    for experiment in experiment_list:\n",
    "        if experiment.get('feature_extraction') is not None:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4258d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(studies_list)\n",
    "experiment_df['num_experiments'] = experiment_df['ml_approaches'].apply(lambda x: len(x))\n",
    "experiment_df['exp_with_feat_extract'] = experiment_df['ml_approaches'].apply(lambda x: experiments_with_feat_ext(x))\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16239754",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = experiment_df['num_experiments'].sum()\n",
    "num_experiments_with_feat_ext = experiment_df['exp_with_feat_extract'].sum()\n",
    "\n",
    "print(f\"Total number of experiments: {num_experiments}\")\n",
    "print(f\"Number of experiments with feature extracttion: {num_experiments_with_feat_ext}\")\n",
    "print(f\"NUmber of exoeriments with out feature extraction: {num_experiments-num_experiments_with_feat_ext}\")\n",
    "print(f\"Percentage of experiments with feature extraction: {num_experiments_with_feat_ext/num_experiments*100:.2f}%\")\n",
    "print(f\"Number of papers: {experiment_df['doi'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_technique_name(technique):\n",
    "    \"\"\"\n",
    "    Clean technique names by extracting the base strategy.\n",
    "    Handles both colon-separated and parentheses-separated details.\n",
    "    \"\"\"\n",
    "    if not isinstance(technique, str):\n",
    "        return str(technique)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    cleaned = technique.strip()\n",
    "    \n",
    "    # Handle specific name standardizations first\n",
    "    if cleaned == \"Short Term Fourier Transform\" or cleaned == \"Short Time Fourier Transform\" or cleaned == \"Short-Term Fourier Transform\":\n",
    "        cleaned = \"Short-Time Fourier Transform\"\n",
    "\n",
    "    if cleaned == \"Wave2Vec2\" or cleaned == \"Wav2Vec\" or cleaned == \"Wave2Vec2.0\" or cleaned == \"Wav2Vec2\":\n",
    "        cleaned = \"Wave2Vec\"\n",
    "    if \"wav2vec\" in cleaned.lower():\n",
    "        cleaned = \"Wave2Vec\"\n",
    "\n",
    "    if cleaned == \"Articulation features\":\n",
    "        cleaned = \"Articulation Features\"\n",
    "\n",
    "    if \"resnet\" in cleaned.lower():\n",
    "        cleaned = \"ResNet\"\n",
    "\n",
    "    if \"Phonation features\" == cleaned:\n",
    "        cleaned = \"Phonation Features\"\n",
    "    \n",
    "    # Spectrogram harmonization\n",
    "    if (cleaned == \"Spectograms\" or \n",
    "        cleaned == \"Spectrogram-color\" or \n",
    "        cleaned == \"Spectrogram-grayscale\" or \n",
    "        cleaned == \"Gray Scale Spectrogram\" or\n",
    "        cleaned == \"Color Spectrogram\"):\n",
    "        cleaned = \"Spectrogram\"\n",
    "    \n",
    "    # Mel-Spectrogram harmonization\n",
    "    if cleaned == \"Mel-Spectogram\" or cleaned == \"Mel-Spectrogram\" or cleaned == \"Mel Spectrogram\" or cleaned == \"Mel Spectrograms\":\n",
    "        cleaned = \"Mel-Spectrogram\"\n",
    "    \n",
    "    # MFCC harmonization\n",
    "    if (cleaned == \"Mel Frequency Cepstral Coefficients\" or \n",
    "        cleaned == \"Mel-Frequency Cepstral Coefficients-mean\" or \n",
    "        cleaned == \"Mel-Frequency Cepstral Coefficients-variance\" or \n",
    "        cleaned == \"Mel-Frequency Cepstrum Coefficients\"):\n",
    "        cleaned = \"Mel-Frequency Cepstral Coefficients\"\n",
    "\n",
    "    if \"First Three Formants\" in cleaned:\n",
    "        cleaned = \"First Three Formants\"\n",
    "\n",
    "    # Handle colon-separated details (e.g., \"Wavelet Transform: Daubechies\")\n",
    "    if ':' in cleaned:\n",
    "        cleaned = cleaned.split(':')[0].strip()\n",
    "    \n",
    "    # Handle parentheses details (e.g., \"MFCC (Mel-Frequency Cepstral Coefficients)\")\n",
    "    if '(' in cleaned:\n",
    "        cleaned = cleaned.split('(')[0].strip()\n",
    "    \n",
    "    # Handle bracket details (e.g., \"FFT [Fast Fourier Transform]\")\n",
    "    if '[' in cleaned:\n",
    "        cleaned = cleaned.split('[')[0].strip()\n",
    "    \n",
    "    # Additional cleanup for common patterns\n",
    "    # Remove trailing dashes or other separators\n",
    "    cleaned = cleaned.rstrip(' -â€“â€”_')\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5421190",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['feat_extraction'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_feature_extraction(x)\n",
    ")\n",
    "\n",
    "extraction_df = experiment_df.explode('feat_extraction')\n",
    "extraction_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_df['cleaned_technique'] = extraction_df['feat_extraction'].apply(clean_technique_name)\n",
    "extraction_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacee11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique techniques: {extraction_df['cleaned_technique'].nunique():,}\")\n",
    "print(f\"Total of papers: {extraction_df['doi'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8931d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = extraction_df.groupby(by='doi', as_index=False).agg({'cleaned_technique': set})\n",
    "tech_by_paper = tech_by_paper.explode('cleaned_technique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2383266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct logic: use sets to find mutually exclusive and overlapping groups\n",
    "mask_no_feature_extraction = (tech_by_paper['cleaned_technique'] == 'nan')\n",
    "mask_feature_extraction = (tech_by_paper['cleaned_technique'] != 'nan')\n",
    "\n",
    "dois_no_feat_ext = set(tech_by_paper[mask_no_feature_extraction]['doi'])\n",
    "dois_feat_ext = set(tech_by_paper[mask_feature_extraction]['doi'])\n",
    "\n",
    "only_no_feat_ext = dois_no_feat_ext - dois_feat_ext\n",
    "only_feat_ext = dois_feat_ext - dois_no_feat_ext\n",
    "both_types = dois_no_feat_ext & dois_feat_ext\n",
    "\n",
    "print(f\"Total of papers without feature extraction only: {len(only_no_feat_ext):,}\")\n",
    "print(f\"Papers with feature extraction only: {len(only_feat_ext):,}\")\n",
    "print(f\"Papers with both feature extraction and no feature extraction entries: {len(both_types):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb042d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = tech_by_paper[tech_by_paper['doi'].isin(dois_feat_ext)].reset_index(drop=True)\n",
    "tech_by_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_rank = tech_by_paper['cleaned_technique'].value_counts().reset_index()\n",
    "technique_rank.columns = ['technique', 'count']\n",
    "technique_rank['percentage'] = np.round(technique_rank['count'] / technique_rank['count'].sum() * 100, 2)\n",
    "technique_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84022432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def break_long_names(name, max_len=22, max_lines=3):\n",
    "    wrapped = textwrap.wrap(\n",
    "        name,\n",
    "        width=max_len,\n",
    "        break_long_words=False,\n",
    "        break_on_hyphens=False\n",
    "    )\n",
    "\n",
    "    # Limit number of lines\n",
    "    if len(wrapped) > max_lines:\n",
    "        wrapped = wrapped[:max_lines]\n",
    "        wrapped[-1] += \"â€¦\"\n",
    "\n",
    "    return \"\\n\".join(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc60058",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_techniques = technique_rank.head(10)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Figure size (single-column journal size)\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = top10_techniques['percentage']\n",
    "\n",
    "# Bar plot\n",
    "ax = sns.barplot(\n",
    "    x=top10_techniques['count'],\n",
    "    y=top10_techniques['technique'],\n",
    "    color=\"#4C72B0\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Most Used Feature Extraction Techniques\", fontsize=18, pad=12)\n",
    "ax.set_xlabel(\"Number of Papers\", fontsize=14)\n",
    "ax.set_ylabel(\"Feature Extraction Technique\", fontsize=14)\n",
    "\n",
    "# Ticks\n",
    "ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "# Add value and percentage labels on bars (closer to the end of the bars)\n",
    "for i, (v, pct) in enumerate(zip(top10_techniques['count'], percentages)):\n",
    "    ax.text(v - 0.5, i, f\"{pct:.1f}%\", va='center', ha='right', fontsize=12, fontweight='bold', color='white')\n",
    "\n",
    "# Improve grid appearance\n",
    "ax.grid(axis='x', color=\"#E5E5E5\")\n",
    "ax.grid(axis='y', visible=False)\n",
    "\n",
    "# Tight layout for clean export\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_ext_barplot.svg'), dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_techniques = tech_by_paper.groupby('doi').agg({'cleaned_technique': set})\n",
    "mult_techniques['num_techniques'] = mult_techniques['cleaned_technique'].apply(lambda x: len(x))\n",
    "mult_techniques.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584235e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_no_feature = mask_no_feature_extraction.sum()\n",
    "num_one_technique = mult_techniques[mult_techniques['num_techniques'] == 1].shape[0]\n",
    "num_multiple_techniques = mult_techniques[mult_techniques['num_techniques'] > 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the stacked bar plot (single horizontal stacked bar, no y-label)\n",
    "categories = ['']  # Empty string to hide y-label\n",
    "counts = [len(only_no_feat_ext), num_one_technique, num_multiple_techniques]\n",
    "labels = ['No Feature Extraction', 'One Technique', 'Multiple Techniques']\n",
    "\n",
    "# Calculate percentages\n",
    "total_papers = sum(counts)\n",
    "percentages = [count/total_papers*100 for count in counts]\n",
    "\n",
    "# Create the horizontal stacked bar plot\n",
    "plt.figure(figsize=(9, 2))\n",
    "\n",
    "# Colors for each segment\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "lefts = 0\n",
    "bars = []\n",
    "for i, (count, color, label, pct) in enumerate(zip(counts, colors, labels, percentages)):\n",
    "    bar = plt.barh(categories, count, left=lefts, color=color, edgecolor='black', linewidth=1.5, label=f'{label} ({count}, {pct:.1f}%)')\n",
    "    # Add value and percentage label in the middle of each segment\n",
    "    plt.text(lefts + count/2, 0, f'{count}\\n({pct:.1f}%)', va='center', ha='center', fontsize=11, fontweight='bold', color='white')\n",
    "    lefts += count\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Feature Extraction Usage in Papers', fontsize=16, pad=20)\n",
    "plt.xlabel('Number of Papers', fontsize=14)\n",
    "plt.yticks([])  # Remove y-tick label\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=11)\n",
    "\n",
    "# Set x-axis to show integers only\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_ext_stacked.svg'), dpi=600)\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Total papers analyzed: {total_papers}\")\n",
    "print(f\"Papers with no feature extraction: {len(only_no_feat_ext)} ({percentages[0]:.1f}%)\")\n",
    "print(f\"Papers with one technique: {num_one_technique} ({percentages[1]:.1f}%)\")\n",
    "print(f\"Papers with multiple techniques: {num_multiple_techniques} ({percentages[2]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis\n",
    "\n",
    "top5_techniques = top10_techniques.head(5)\n",
    "\n",
    "df_temporal = pd.merge(\n",
    "    tech_by_paper, \n",
    "    experiment_df.groupby(by='doi').agg({'year': 'first'}).reset_index(), \n",
    "    on='doi', how='left'\n",
    ")\n",
    "df_temporal = df_temporal[df_temporal['cleaned_technique'].isin(top5_techniques['technique'])].reset_index(drop=True)\n",
    "df_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count techniques by year\n",
    "temporal_counts = df_temporal.groupby(['year', 'cleaned_technique']).size().reset_index(name='count')\n",
    "\n",
    "# Create a pivot table for easier plotting\n",
    "temporal_pivot = temporal_counts.pivot(index='year', columns='cleaned_technique', values='count').fillna(0)\n",
    "\n",
    "# Sort columns by total usage (descending)\n",
    "col_order = temporal_pivot.sum().sort_values(ascending=False).index\n",
    "temporal_pivot = temporal_pivot[col_order]\n",
    "\n",
    "temporal_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create line plot showing temporal trends\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot each technique\n",
    "for technique in temporal_pivot.columns:\n",
    "    plt.plot(temporal_pivot.index, temporal_pivot[technique], marker='o', linewidth=2, label=technique)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Temporal Trends of Top 10 Feature Extraction Techniques', fontsize=16, pad=20)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Papers', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Set integer ticks for both axes\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_ext_temporal_trends.svg'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Stacked bar plot for temporal trends\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "bottoms = np.zeros(len(temporal_pivot.index))\n",
    "for technique in temporal_pivot.columns:\n",
    "    plt.bar(temporal_pivot.index, temporal_pivot[technique], bottom=bottoms, label=technique)\n",
    "    bottoms += temporal_pivot[technique].values\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Temporal Trends of Top 5 Feature Extraction Techniques (Stacked Bar)', fontsize=16, pad=20)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Papers', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, linestyle='--', axis='y')\n",
    "\n",
    "# Set integer ticks\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.gca().yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_ext_temporal_stacked_bar.svg'), dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Diagnosis_Severity_PD_Voice\"]\n",
    "collection = db[\"studies\"]\n",
    "\n",
    "print(\"ðŸ”„ Loading studies from MongoDB...\")\n",
    "fields_to_extract = {\n",
    "    \"doi\"             : 1, \n",
    "    \"year\"            : 1, \n",
    "    \"study_id\"        : 1,\n",
    "    \"ml_approaches\"   : 1,\n",
    "    \"source_dataset\"   : 1,\n",
    "    '_id'             : 0\n",
    "}  # 1 = include, 0 = exclude\n",
    "studies_cursor = collection.find({}, fields_to_extract)\n",
    "studies_list = list(studies_cursor)\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total studies loaded: {len(studies_list)}\")\n",
    "print(f\"ðŸ“„ Sample document keys: {list(studies_list[0].keys()) if studies_list else 'No documents found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c377400",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(studies_list)\n",
    "experiment_df['exp_with_feat_extract'] = experiment_df['ml_approaches'].apply(lambda x: experiments_with_feat_ext(x))\n",
    "experiment_df['feat_extraction'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_feature_extraction(x)\n",
    ")\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22dbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = experiment_df[experiment_df['exp_with_feat_extract'] > 0].reset_index(drop=True)\n",
    "experiment_df['source_dataset'] = experiment_df['source_dataset'].apply(\n",
    "    lambda x: x[0].get('name')\n",
    ")\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cdb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = experiment_df.explode('feat_extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = experiment_df[['doi', 'source_dataset', 'feat_extraction']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61098219",
   "metadata": {},
   "outputs": [],
   "source": [
    "short[short['source_dataset'] == \"Oxford Parkinson's Disease Detection Dataset\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373fd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal[df_temporal['cleaned_technique']=='Wave2Vec']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-db-Uw6PKE_M-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
