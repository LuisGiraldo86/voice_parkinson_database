{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1729f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "library_path = os.path.abspath('..')\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "\n",
    "PLOTS_PATH = os.path.join(library_path, 'plots')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Diagnosis_Severity_PD_Voice\"]\n",
    "collection = db[\"studies\"]\n",
    "\n",
    "print(\"ðŸ”„ Loading studies from MongoDB...\")\n",
    "fields_to_extract = {\n",
    "    \"doi\"             : 1, \n",
    "    \"title\"           : 1,\n",
    "    \"year\"            : 1, \n",
    "    \"study_id\"        : 1,\n",
    "    \"ml_approaches\"   : 1,\n",
    "    '_id'             : 0\n",
    "}  # 1 = include, 0 = exclude\n",
    "studies_cursor = collection.find({}, fields_to_extract)\n",
    "studies_list = list(studies_cursor)\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total studies loaded: {len(studies_list)}\")\n",
    "print(f\"ðŸ“„ Sample document keys: {list(studies_list[0].keys()) if studies_list else 'No documents found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_selection(experiment_list:list)->list:\n",
    "\n",
    "    feat_extract = []\n",
    "\n",
    "    for experiment in experiment_list:\n",
    "        selection_pipe = experiment.get('feature_selection')\n",
    "        if selection_pipe is None:\n",
    "            selection_pipe = []\n",
    "        else:\n",
    "            selection_pipe = selection_pipe.get('methods', [])\n",
    "        feat_extract += selection_pipe\n",
    "\n",
    "    return list(set(feat_extract))\n",
    "\n",
    "def experiments_with_feat_sel(experiment_list: list)->int:\n",
    "\n",
    "    count = 0\n",
    "    for experiment in experiment_list:\n",
    "        if experiment.get('feature_selection') is not None:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a390926",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(studies_list)\n",
    "experiment_df['num_experiments'] = experiment_df['ml_approaches'].apply(lambda x: len(x))\n",
    "experiment_df['exp_with_feat_sel'] = experiment_df['ml_approaches'].apply(lambda x: experiments_with_feat_sel(x))\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef741855",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = experiment_df['num_experiments'].sum()\n",
    "experiments_with_feat_sel = experiment_df['exp_with_feat_sel'].sum()\n",
    "\n",
    "print(f\"Total number of experiments: {num_experiments}\")\n",
    "print(f\"Number of experiments with feature selection: {experiments_with_feat_sel}\")\n",
    "print(f\"NNumber of experiments without feature selection: {num_experiments-experiments_with_feat_sel}\")\n",
    "print(f\"Percentage of experiments with feature selection: {experiments_with_feat_sel/num_experiments*100:.2f}%\")\n",
    "print(f\"Number of papers: {experiment_df['doi'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff318a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_technique_name(technique):\n",
    "    \"\"\"\n",
    "    Clean technique names by extracting the base strategy.\n",
    "    Handles both colon-separated and parentheses-separated details.\n",
    "    \"\"\"\n",
    "    if not isinstance(technique, str):\n",
    "        return str(technique)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    cleaned = technique.strip()\n",
    "    \n",
    "    # Handle colon-separated details (e.g., \"Recursive Feature Elimination: XGBoost\")\n",
    "    if ':' in cleaned:\n",
    "        cleaned = cleaned.split(':')[0].strip()\n",
    "    \n",
    "    # Handle parentheses details (e.g., \"PCA (Principal Component Analysis)\")\n",
    "    if '(' in cleaned:\n",
    "        cleaned = cleaned.split('(')[0].strip()\n",
    "    \n",
    "    # Handle bracket details (e.g., \"LASSO [L1 Regularization]\")\n",
    "    if '[' in cleaned:\n",
    "        cleaned = cleaned.split('[')[0].strip()\n",
    "    \n",
    "    # Additional cleanup for common patterns\n",
    "    # Remove trailing dashes or other separators\n",
    "    cleaned = cleaned.rstrip(' -â€“â€”_')\n",
    "\n",
    "    if cleaned.lower() == 't-test':\n",
    "        cleaned = 'T-test'\n",
    "\n",
    "    if cleaned.lower() == 'borutta':\n",
    "        cleaned = 'Boruta'\n",
    "\n",
    "    if cleaned.lower() == 'extra trees':\n",
    "        cleaned = 'Extra Tree'\n",
    "\n",
    "    if cleaned.lower() == 'f-score':\n",
    "        cleaned = 'Fisher Score'\n",
    "\n",
    "    if cleaned.lower() == 'relief':\n",
    "        cleaned = 'ReliefF'\n",
    "\n",
    "    if cleaned == 'Gray Wolf Optimization':\n",
    "        cleaned = 'Grey Wolf Optimization'\n",
    "\n",
    "    if cleaned == 'Sequential Forward Selection' or cleaned == 'Sequential Feature Selection':\n",
    "        cleaned = 'Sequential Forward Feature Selection'\n",
    "\n",
    "    if cleaned == 'Backward Stepwise Regression' or cleaned == 'Sequential Backward Selection':\n",
    "        cleaned = 'Backward Stepwise Selection'\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['feat_selection'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_feature_selection(x)\n",
    ")\n",
    "\n",
    "selection_df = experiment_df.explode('feat_selection')\n",
    "selection_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9378fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df['doi'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df['cleaned_technique'] = selection_df['feat_selection'].apply(clean_technique_name)\n",
    "selection_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique techniques: {selection_df['cleaned_technique'].nunique():,}\")\n",
    "print(f\"Total of papers: {selection_df['doi'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = selection_df.groupby(by='doi', as_index=False).agg({'cleaned_technique': set})\n",
    "tech_by_paper = tech_by_paper.explode('cleaned_technique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305de5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct logic: use sets to find mutually exclusive and overlapping groups\n",
    "mask_no_feature_extraction = (tech_by_paper['cleaned_technique'] == 'nan')\n",
    "mask_feature_extraction = (tech_by_paper['cleaned_technique'] != 'nan')\n",
    "\n",
    "dois_no_feat_ext = set(tech_by_paper[mask_no_feature_extraction]['doi'])\n",
    "dois_feat_ext = set(tech_by_paper[mask_feature_extraction]['doi'])\n",
    "\n",
    "only_no_feat_ext = dois_no_feat_ext - dois_feat_ext\n",
    "only_feat_ext = dois_feat_ext - dois_no_feat_ext\n",
    "both_types = dois_no_feat_ext & dois_feat_ext\n",
    "\n",
    "print(f\"Total of papers without feature extraction only: {len(only_no_feat_ext):,}\")\n",
    "print(f\"Papers with feature extraction only: {len(only_feat_ext):,}\")\n",
    "print(f\"Papers with both feature extraction and no feature extraction entries: {len(both_types):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = tech_by_paper[tech_by_paper['doi'].isin(dois_feat_ext)].reset_index(drop=True)\n",
    "tech_by_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_rank = tech_by_paper['cleaned_technique'].value_counts().reset_index()\n",
    "technique_rank.columns = ['technique', 'count']\n",
    "technique_rank['percentage'] = np.round(technique_rank['count'] / technique_rank['count'].sum() * 100, 2)\n",
    "technique_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb768edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_tech = technique_rank.sort_values('technique')\n",
    "alpha_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b830f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def break_long_names(name, max_len=22, max_lines=3):\n",
    "    wrapped = textwrap.wrap(\n",
    "        name,\n",
    "        width=max_len,\n",
    "        break_long_words=False,\n",
    "        break_on_hyphens=False\n",
    "    )\n",
    "\n",
    "    # Limit number of lines\n",
    "    if len(wrapped) > max_lines:\n",
    "        wrapped = wrapped[:max_lines]\n",
    "        wrapped[-1] += \"â€¦\"\n",
    "\n",
    "    return \"\\n\".join(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05104de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_techniques = technique_rank.head(10)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Figure size (single-column journal size)\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = top10_techniques['percentage']\n",
    "\n",
    "# Bar plot\n",
    "ax = sns.barplot(\n",
    "    x=top10_techniques['count'],\n",
    "    y=top10_techniques['technique'],\n",
    "    color=\"#4C72B0\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Most Used Feature Selection Techniques\", fontsize=18, pad=12)\n",
    "ax.set_xlabel(\"Number of Papers\", fontsize=14)\n",
    "ax.set_ylabel(\"Feature Selection Technique\", fontsize=14)\n",
    "\n",
    "# Ticks\n",
    "ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "# Add value and percentage labels on bars (closer to the end of the bars)\n",
    "for i, (v, pct) in enumerate(zip(top10_techniques['count'], percentages)):\n",
    "    ax.text(v - 0.5, i, f\"{pct:.1f}%\", va='center', ha='right', fontsize=12, fontweight='bold', color='white')\n",
    "\n",
    "# Improve grid appearance\n",
    "ax.grid(axis='x', color=\"#E5E5E5\")\n",
    "ax.grid(axis='y', visible=False)\n",
    "\n",
    "# Tight layout for clean export\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_sel_barplot.svg'), dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47047422",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_techniques = tech_by_paper.groupby('doi').agg({'cleaned_technique': set})\n",
    "mult_techniques['num_techniques'] = mult_techniques['cleaned_technique'].apply(lambda x: len(x))\n",
    "mult_techniques.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_one_technique = mult_techniques[mult_techniques['num_techniques'] == 1].shape[0]\n",
    "num_multiple_techniques = mult_techniques[mult_techniques['num_techniques'] > 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for the stacked bar plot (single horizontal stacked bar, no y-label)\n",
    "categories = ['']  # Empty string to hide y-label\n",
    "counts = [len(only_no_feat_ext), num_one_technique, num_multiple_techniques]\n",
    "labels = ['No Feature Extraction', 'One Technique', 'Multiple Techniques']\n",
    "\n",
    "# Calculate percentages\n",
    "total_papers = sum(counts)\n",
    "percentages = [count/total_papers*100 for count in counts]\n",
    "\n",
    "# Create the horizontal stacked bar plot\n",
    "plt.figure(figsize=(9, 2))\n",
    "\n",
    "# Colors for each segment\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "lefts = 0\n",
    "bars = []\n",
    "for i, (count, color, label, pct) in enumerate(zip(counts, colors, labels, percentages)):\n",
    "    bar = plt.barh(categories, count, left=lefts, color=color, edgecolor='black', linewidth=1.5, label=f'{label} ({count}, {pct:.1f}%)')\n",
    "    # Add value and percentage label in the middle of each segment\n",
    "    plt.text(lefts + count/2, 0, f'{count}\\n({pct:.1f}%)', va='center', ha='center', fontsize=11, fontweight='bold', color='white')\n",
    "    lefts += count\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Distribution of Feature Selection Usage in Papers', fontsize=16, pad=20)\n",
    "plt.xlabel('Number of Papers', fontsize=14)\n",
    "plt.yticks([])  # Remove y-tick label\n",
    "\n",
    "# Add legend\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=11)\n",
    "\n",
    "# Set x-axis to show integers only\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Add grid for better readability\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'feat_selection_stacked.svg'), dpi=600)\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Total papers analyzed: {total_papers}\")\n",
    "print(f\"Papers with no feature extraction: {len(only_no_feat_ext)} ({percentages[0]:.1f}%)\")\n",
    "print(f\"Papers with one technique: {num_one_technique} ({percentages[1]:.1f}%)\")\n",
    "print(f\"Papers with multiple techniques: {num_multiple_techniques} ({percentages[2]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments_with_feat_ext_selection(experiment_list: list)->dict:\n",
    "\n",
    "    counter = {\n",
    "        'feat_ext_only': 0,\n",
    "        'feat_sel_only': 0,\n",
    "        'both': 0,\n",
    "        'neither': 0\n",
    "    }\n",
    "    for experiment in experiment_list:\n",
    "\n",
    "        has_feature_extraction = experiment.get('feature_extraction') is not None\n",
    "        has_feature_selection = experiment.get('feature_selection') is not None\n",
    "\n",
    "        if has_feature_extraction and has_feature_selection:\n",
    "            counter['both'] += 1\n",
    "        elif has_feature_extraction and not has_feature_selection:\n",
    "            counter['feat_ext_only'] += 1\n",
    "        elif has_feature_selection and not has_feature_extraction:\n",
    "            counter['feat_sel_only'] += 1\n",
    "        else:\n",
    "            counter['neither'] += 1\n",
    "    return counter\n",
    "\n",
    "def experiment_meta_counter(experiment_collection)->dict:\n",
    "\n",
    "    total_counter = {\n",
    "        'feat_ext_only': 0,\n",
    "        'feat_sel_only': 0,\n",
    "        'both': 0,\n",
    "        'neither': 0\n",
    "    }\n",
    "\n",
    "    for experiment in experiment_collection:\n",
    "        exp_counter = experiments_with_feat_ext_selection(experiment)\n",
    "        for key in total_counter.keys():\n",
    "            total_counter[key] += exp_counter[key]\n",
    "\n",
    "    return total_counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def paper_meta_counter(data_df: pd.DataFrame,doi_col: str, experiment_col: str)->pd.DataFrame:\n",
    "\n",
    "    summary_df = pd.DataFrame(columns=['doi', 'feat_ext_only', 'feat_sel_only', 'both', 'neither'])\n",
    "\n",
    "    \n",
    "\n",
    "    for idx, row in data_df.iterrows():\n",
    "        doi = row[doi_col]\n",
    "        experiment_collection = row[experiment_col]\n",
    "\n",
    "        exp_counter = experiments_with_feat_ext_selection(experiment_collection)\n",
    "\n",
    "        exp_counter['doi'] = doi\n",
    "\n",
    "        summary_df = pd.concat([summary_df, pd.DataFrame([exp_counter])], ignore_index=True)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72008f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_with_feat_ext_selection(experiment_df['ml_approaches'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_meta_counter(experiment_df['ml_approaches'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = paper_meta_counter(experiment_df, 'doi', 'ml_approaches')\n",
    "summary_df = summary_df.groupby(by='doi').sum().reset_index()\n",
    "summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8da681",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_extraction = (summary_df['feat_ext_only'] == 0)\n",
    "mask_no_selection = (summary_df['feat_sel_only'] == 0)\n",
    "mask_both = (summary_df['both'] > 0)\n",
    "mask_neither = (summary_df['neither'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c96d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[mask_both].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df[~mask_both & mask_no_extraction & mask_no_selection & mask_neither].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df[selection_df['cleaned_technique']=='Hybrid Grey Wolf-Whale Optimization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_df['cleaned_technique'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-db-Uw6PKE_M-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
