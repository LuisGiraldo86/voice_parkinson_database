{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "library_path = os.path.abspath('..')\n",
    "if library_path not in sys.path:\n",
    "    sys.path.append(library_path)\n",
    "\n",
    "PLOTS_PATH = os.path.join(library_path, 'plots')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Diagnosis_Severity_PD_Voice\"]\n",
    "collection = db[\"studies\"]\n",
    "\n",
    "print(\"ðŸ”„ Loading studies from MongoDB...\")\n",
    "fields_to_extract = {\n",
    "    \"doi\"             : 1, \n",
    "    \"year\"            : 1, \n",
    "    \"study_id\"        : 1,\n",
    "    \"ml_approaches\"   : 1,\n",
    "    '_id'             : 0\n",
    "}  # 1 = include, 0 = exclude\n",
    "studies_cursor = collection.find({}, fields_to_extract)\n",
    "studies_list = list(studies_cursor)\n",
    "\n",
    "\n",
    "print(f\"ðŸ“Š Total studies loaded: {len(studies_list)}\")\n",
    "print(f\"ðŸ“„ Sample document keys: {list(studies_list[0].keys()) if studies_list else 'No documents found'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaling(experiment_list:list)->list:\n",
    "\n",
    "    scaling_list = []\n",
    "\n",
    "    for experiment in experiment_list:\n",
    "        scaling = experiment.get('scaling')\n",
    "        if scaling is None:\n",
    "            scaling = []\n",
    "        scaling_list += scaling\n",
    "\n",
    "    return list(set(scaling_list))\n",
    "\n",
    "def experiments_with_scaling(experiment_list: list)->int:\n",
    "\n",
    "    count = 0\n",
    "    for experiment in experiment_list:\n",
    "        if experiment.get('scaling') is not None:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = pd.DataFrame(studies_list)\n",
    "experiment_df['num_experiments'] = experiment_df['ml_approaches'].apply(lambda x: len(x))\n",
    "experiment_df['exp_with_scaling'] = experiment_df['ml_approaches'].apply(lambda x: experiments_with_scaling(x))\n",
    "experiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = experiment_df['num_experiments'].sum()\n",
    "experiments_with_scaling = experiment_df['exp_with_scaling'].sum()\n",
    "\n",
    "print(f\"Total number of experiments: {num_experiments}\")\n",
    "print(f\"Number of experiments with scaling: {experiments_with_scaling}\")\n",
    "print(f\"NNumber of experiments without scaling: {num_experiments-experiments_with_scaling}\")\n",
    "print(f\"Percentage of experiments with scaling: {experiments_with_scaling/num_experiments*100:.2f}%\")\n",
    "print(f\"Number of papers: {experiment_df['doi'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23918c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df['scaling'] = experiment_df['ml_approaches'].apply(\n",
    "    lambda x: get_scaling(x)\n",
    ")\n",
    "\n",
    "scaling_df = experiment_df.explode('scaling')\n",
    "scaling_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4351e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique techniques: {scaling_df['scaling'].nunique():,}\")\n",
    "print(f\"Total of papers: {scaling_df['doi'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa57345",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = scaling_df.groupby(by='doi', as_index=False).agg({'scaling': set})\n",
    "tech_by_paper = tech_by_paper.explode('scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07881a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct logic: use sets to find mutually exclusive and overlapping groups\n",
    "mask_no_scaling = (tech_by_paper['scaling'].isna())\n",
    "mask_scaling = (tech_by_paper['scaling'].notna())\n",
    "\n",
    "dois_no_feat_ext = set(tech_by_paper[mask_no_scaling]['doi'])\n",
    "dois_feat_ext = set(tech_by_paper[mask_scaling]['doi'])\n",
    "\n",
    "only_no_scaling = dois_no_feat_ext - dois_feat_ext\n",
    "only_scaling = dois_feat_ext - dois_no_feat_ext\n",
    "both_types = dois_no_feat_ext & dois_feat_ext\n",
    "\n",
    "print(f\"Total of papers without scaling only: {len(only_no_scaling):,}\")\n",
    "print(f\"Papers with scaling only: {len(only_scaling):,}\")\n",
    "print(f\"Papers with both scaling and no scaling entries: {len(both_types):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee32788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_by_paper = tech_by_paper[tech_by_paper['doi'].isin(only_scaling)].reset_index(drop=True)\n",
    "tech_by_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_rank = tech_by_paper['scaling'].value_counts().reset_index()\n",
    "technique_rank.columns = ['technique', 'count']\n",
    "technique_rank['percentage'] = np.round(technique_rank['count'] / technique_rank['count'].sum() * 100, 2)\n",
    "technique_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b839efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def break_long_names(name, max_len=22, max_lines=3):\n",
    "    wrapped = textwrap.wrap(\n",
    "        name,\n",
    "        width=max_len,\n",
    "        break_long_words=False,\n",
    "        break_on_hyphens=False\n",
    "    )\n",
    "\n",
    "    # Limit number of lines\n",
    "    if len(wrapped) > max_lines:\n",
    "        wrapped = wrapped[:max_lines]\n",
    "        wrapped[-1] += \"â€¦\"\n",
    "\n",
    "    return \"\\n\".join(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_techniques = technique_rank.head(3)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Figure size (single-column journal size)\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Calculate percentages\n",
    "percentages = top3_techniques['percentage']\n",
    "\n",
    "# Bar plot\n",
    "ax = sns.barplot(\n",
    "    x=top3_techniques['count'],\n",
    "    y=top3_techniques['technique'],\n",
    "    color=\"#4C72B0\",\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Most Used Feature Extraction Techniques\", fontsize=18, pad=12)\n",
    "ax.set_xlabel(\"Number of Papers\", fontsize=14)\n",
    "ax.set_ylabel(\"Feature Extraction Technique\", fontsize=14)\n",
    "\n",
    "# Ticks\n",
    "ax.tick_params(axis='both', labelsize=11)\n",
    "\n",
    "# Add value and percentage labels on bars (closer to the end of the bars)\n",
    "for i, (v, pct) in enumerate(zip(top3_techniques['count'], percentages)):\n",
    "    ax.text(v - 0.4, i, f\"{pct:.1f}%\", va='center', ha='right', fontsize=11, fontweight='bold', color='white')\n",
    "\n",
    "# Improve grid appearance\n",
    "ax.grid(axis='x', color=\"#E5E5E5\")\n",
    "ax.grid(axis='y', visible=False)\n",
    "\n",
    "# Tight layout for clean export\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'scaling_barplot.svg'), dpi=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice-db-M3sIqRqH-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
